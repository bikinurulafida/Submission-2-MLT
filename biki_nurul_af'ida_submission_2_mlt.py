# -*- coding: utf-8 -*-
"""Biki Nurul Af'ida_Submission 2 MLT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JopjPmlzcFmpoKg56CIHWDcrPDHQQIhx

# Library
"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Data Loading

Data yang digunakan adalah dataset Goodreads-books yang bersumber dari Kaggle (https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks/data?select=books.csv)
"""

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Load the data with the appropriate delimiter, using the python engine and skipping bad lines
data = pd.read_csv('/content/drive/MyDrive/DBS/Data/books.csv', delimiter=',', engine='python', on_bad_lines='skip')

# Set 'bookID' as the index
data.set_index('bookID', inplace=True)

# Display the first few rows to check
data.head()

"""# Explaratory Data Analysis - Deskripsi Peubah

Berdasarkan informasi dari Kaggle, peubah-peubah pada dataset adalah sebagai berikut:

- Title: Nama buku yang terdaftar di platform Goodreads (peubah kategorikal)
- Author: Nama penulis buku (peubah kategorika)
- Average rating: Rata-rata rating yang diberikan pengguna untuk buku tersebut di Goodreads (peubah kontinu)
- ISBN: Nomor ISBN buku yang digunakan untuk identifikasi unik (peubah kategorikal)
- ISBN13: Nomor ISBN-13 buku, versi terbaru dari ISBN (peubah kategorikal)
- Language Code: Kode bahasa buku, misalnya "eng" untuk Bahasa Inggris (peubah kategorikal)
- Num Pages: Jumlah halaman dalam buku (peubah kontinu)
- Ratings Count: Jumlah total rating yang diterima oleh buku (peubah kontinu)
Text Review Count: Jumlah ulasan teks yang ditulis oleh pengguna (peubah kontinu)
- Publication Date: Tanggal penerbitan buku (peubah kategorikal)
- Publisher: Nama penerbit buku (peubah kategorikal)
"""

data.info()

data.describe()

data.shape

"""Dataset terdiri dari 11119 baris data dan 11 kolom.

# Univariate Exploratory Data Analysis

## Peubah Title
"""

data['title'].info()

print('Banyak data: ', len(data['title'].unique()))

print('Judul Buku: ', data['title'].unique())

"""Terdapat 10.344 judul buku berbeda

## Peubah Authors
"""

data['authors'].info()

print('Banyak data: ', len(data['authors'].unique()))

print('Authors: ', data['authors'].unique())

"""Terdapat 6.635 authors berbeda.

## Peubah Average Rating
"""

data['average_rating'].info()

data['average_rating'].describe()

"""Dapat dilihat bahwa nilai maksimum average rating adalah 5 dan nilai minimumnya adalah 0, dengan rata-ratanya sebesar 3,93

## Peubah Language Code
"""

data['language_code'].info()

print('Banyak Bahasa: ', len(data['language_code'].unique()))

print('Language: ', data['language_code'].unique())

"""Terdapat 27 jenis bahasa.

## Peubah Num Pages
"""

data['  num_pages'].info()

data['  num_pages'].describe()

"""Dapat dilihat halaman maksimal buku adlaah 6576 dan minimumnya adalah 0, dengan rata-rata 336 halaman

## Peubah Ratings Count
"""

data['ratings_count'].info()

data['ratings_count'].describe()

"""Dapat dilihat bahwa ratings count maksimumnya adalah 4,597 dan minimumnya adalah 0.

## Peubah teks reviews count
"""

data['text_reviews_count'].info()

data['text_reviews_count'].describe()

"""Dapat dilihat bahwa text reviews countnya maksimum sebanyak 94.265 dan paling minimum 0.

## Peubah Publication Date

### Mengonversi Peubah Publication Date ke tipe Datetime
"""

data['publication_date'] = pd.to_datetime(data['publication_date'], errors='coerce')
data.info()

data['publication_date'].info()

data['publication_date'].describe()

"""Dapat dilihat bahwa buku dengan publication date terlama adalah pada tanggal 1 Januari 1900 dan yang terbaru adalah 31 Maret 2020.

## Peubah Publisher
"""

data['publisher'].info()

print('Publisher: ', len(data['publisher'].unique()))

"""Terdapat sebanyak 2289 publisher.

# Visualisasi

### Visualisasi Peubah Title
"""

top_titles = data['title'].value_counts().nlargest(10)

plt.figure(figsize=(12, 6))
sns.barplot(x=top_titles.values, y=top_titles.index, palette='viridis')

for i, v in enumerate(top_titles.values):
    plt.text(v + 0.1, i, str(v), color='black', va='center')

plt.title('Top 10 Most Frequent Book Titles')
plt.xlabel('Frequency')
plt.ylabel('Book Title')
plt.tight_layout()
plt.show()

"""Barchart ini menunjukkan 10 judul buku yang paling sering ditemukan dalam dataset. Judul buku yang paling sering muncul adalah The Brothers Karamazov dan The Iliad, masing-masing dengan frekuensi 9 kali. Diikuti oleh beberapa judul lain seperti 'Salem's Lot dan The Odyssey yang muncul sebanyak 8 kali. Barchart ini menggambarkan popularitas berbagai buku dalam koleksi data yang digunakan.

### Visualisasi Peubah Authors
"""

top_authors = data['authors'].value_counts().nlargest(10)
plt.figure(figsize=(12, 6))
sns.barplot(x=top_authors.values, y=top_authors.index, palette='viridis')

for i, v in enumerate(top_authors.values):
    plt.text(v + 0.1, i, str(v), color='black', va='center')

plt.title('Top 10 Most Frequent Authors')
plt.xlabel('Frequency')
plt.ylabel('Author')
plt.tight_layout()
plt.show()

"""Barchart di atas menampilkan 10 penulis yang paling sering muncul dalam dataset. Penulis yang paling sering ditemukan adalah Stephen King dan P.G. Wodehouse, masing-masing dengan 40 kali kemunculan. Penulis lainnya seperti Rumiko Takahashi dan Orson Scott Card juga sering muncul dalam dataset, dengan frekuensi 39 dan 35, masing-masing. Barchart ini menggambarkan dominasi penulis tertentu dalam koleksi buku yang dianalisis.

### Visualisasi Peubah Average Rating
"""

plt.figure(figsize=(8, 5))
sns.histplot(data['average_rating'], bins=20, kde=True, color='skyblue')
plt.title('Distribution of Average Rating')
plt.xlabel('Average Rating')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

"""Grafik di atas menunjukkan distribusi rating rata-rata dari buku-buku dalam dataset. Sebagian besar buku memiliki rating antara 3 hingga 4, dengan frekuensi tertinggi di sekitar 4. Hal ini menunjukkan bahwa sebagian besar buku mendapatkan penilaian yang baik. Namun, ada juga buku dengan rating yang lebih rendah, meskipun jumlahnya lebih sedikit.

### Visualisasi Peubah Language Code
"""

plt.figure(figsize=(10, 6))
sns.countplot(y=data['language_code'], order=data['language_code'].value_counts().index, palette='plasma')

for i, v in enumerate(data['language_code'].value_counts().values):
    plt.text(v + 0.1, i, str(v), color='black', va='center')

plt.title('Count of Books by Language Code')
plt.xlabel('Count')
plt.ylabel('Language Code')
plt.tight_layout()
plt.show()

"""Grafik ini menggambarkan jumlah buku berdasarkan kode bahasa yang terdaftar dalam dataset. Buku dalam bahasa Inggris (kode bahasa eng) mendominasi dengan jumlah yang sangat tinggi, yaitu 8906 buku. Bahasa lainnya seperti Spanyol (spa) dan Inggris (kode en-US dan en-GB) juga memiliki jumlah yang cukup signifikan, meskipun jauh lebih sedikit dibandingkan bahasa Inggris.

### Visualisasi Peubah Num Pages
"""

plt.figure(figsize=(8, 5))
sns.histplot(data['  num_pages'], bins=50, kde=True, color='coral')
plt.title('Distribution of Number of Pages')
plt.xlabel('Number of Pages')
plt.ylabel('Frequency')
plt.xlim(0, data['  num_pages'].quantile(0.99)) # Batasi x-axis untuk melihat distribusi yang lebih jelas
plt.tight_layout()
plt.show()

"""Grafik ini menunjukkan distribusi jumlah halaman buku. Sebagian besar buku memiliki jumlah halaman antara 100 hingga 400 halaman, dengan puncaknya pada sekitar 200 halaman. Buku dengan jumlah halaman lebih sedikit atau lebih banyak sangat jarang ditemukan.

### Visualisasi Peubah Rating Count
"""

plt.figure(figsize=(8, 5))
sns.histplot(data['ratings_count'], bins=50, kde=True, color='purple')
plt.title('Distribution of Ratings Count')
plt.xlabel('Ratings Count')
plt.ylabel('Frequency')
plt.xlim(0, data['ratings_count'].quantile(0.95)) # Batasi x-axis
plt.tight_layout()
plt.show()

"""Grafik ini menggambarkan distribusi jumlah rating yang diterima oleh buku. Kebanyakan buku memiliki jumlah rating yang rendah, dengan sedikit buku yang memiliki ribuan rating. Ini menunjukkan bahwa sebagian besar buku hanya menerima sedikit ulasan atau rating dari pembaca.

### Visualisasi Peubah Text Review Count
"""

plt.figure(figsize=(8, 5))
sns.histplot(data['text_reviews_count'], bins=50, kde=True, color='teal')
plt.title('Distribution of Text Review Count')
plt.xlabel('Text Review Count')
plt.ylabel('Frequency')
plt.xlim(0, data['text_reviews_count'].quantile(0.95)) # Batasi x-axis
plt.tight_layout()
plt.show()

"""Grafik ini menunjukkan distribusi jumlah ulasan teks untuk buku-buku dalam dataset. Sebagian besar buku memiliki ulasan teks yang sedikit, dengan jumlah ulasan yang lebih tinggi secara signifikan pada beberapa buku yang lebih populer. Hal ini mencerminkan bahwa buku dengan ulasan teks lebih banyak cenderung lebih dikenal atau lebih banyak dibaca.

### Visualisasi Peubah Publication Date
"""

data['publication_year'] = pd.to_datetime(data['publication_date'], errors='coerce').dt.year
plt.figure(figsize=(12, 6))
sns.histplot(data['publication_year'].dropna(), bins=50, kde=True, color='olive')
plt.title('Distribution of Publication Year')
plt.xlabel('Publication Year')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()

"""Grafik ini menunjukkan distribusi tahun publikasi buku. Sebagian besar buku diterbitkan antara tahun 2000 hingga 2020, dengan puncaknya terjadi pada tahun 2000. Hal ini menunjukkan bahwa dataset ini didominasi oleh buku-buku yang diterbitkan pada abad ke-21.

### Visualisasi Peubah Publisher
"""

top_publishers = data['publisher'].value_counts().nlargest(10)
plt.figure(figsize=(12, 6))
sns.barplot(x=top_publishers.values, y=top_publishers.index, palette='viridis')

for i, v in enumerate(top_publishers.values):
    plt.text(v + 0.1, i, str(v), color='black', va='center')

plt.title('Top 10 Most Frequent Publishers')
plt.xlabel('Frequency')
plt.ylabel('Publisher')
plt.tight_layout()
plt.show()

"""Barchart di atas menampilkan 10 penerbit buku yang paling sering muncul dalam dataset. Penerbit yang paling sering ditemukan adalah Vintage dengan 318 buku, diikuti oleh Penguin Books dan Penguin Classics. Barchart ini menunjukkan penerbit-penerbit besar yang memiliki kontribusi signifikan terhadap koleksi buku yang dianalisis.

# Data Preparation

## Menyiapkan Data untuk Analisis Rekomendasi

Peubah yang diambil adalah peubah title, authors, language code, dan publisher yang relevan dan merepresentasikan isi dan karakteristik buku.
"""

# Menyiapkan Data untuk Analisis Rekomendasi
df = pd.DataFrame({
    'book_title': data['title'].tolist(),
    'book_author': data['authors'].tolist(),
    'language_code': data['language_code'].tolist(),
    'publisher': data['publisher'].tolist()
})

"""## Mengecek Missing Value"""

pd.DataFrame({'Nilai yang Kosong':df.isna().sum()})

"""Pada dataset tidak terdapat missing values.

## Mengecek Duplikasi Data
"""

duplicate_rows = df[df.duplicated()]
print(f"Jumlah baris duplikat: {len(duplicate_rows)}")
print(duplicate_rows.head())

"""Karena terdapat duplikasi data maka dihapus"""

df.drop_duplicates(inplace=True)
print(f"Jumlah baris setelah menghapus duplikat: {len(df)}")
df.head()

# Concatenate 'title', 'author', 'language_code', 'publisher' into one string column
df['combined_features'] = df['book_title'] + " " + df['book_author'] + " " + df['language_code'] + " " + df['publisher']

"""Menggabungkan peubah yang dipilih.

## TF-IDF Vectorizer

TF-IDF Vektoctorizer digunakan untuk mengubah teks menjadi vektor.
"""

tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['combined_features'])

"""# Modelling

## Cosine Similarity

Menghitung cosine similarity antar buku berdasarkan peubah yang digabungkan.
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim_df = pd.DataFrame(cosine_sim, index=df['book_title'], columns=df['book_title'])

"""## Fungsi Rekomendasi Buku

Digunakan untuk mengambil buku yang paling mirip dengan buku yang diberikan sebagai input berdasarkan kemiripan cosine.
"""

# Function to recommend books based on similarity
def book_recommendations(nama_buku, similarity_data=cosine_sim_df, items=df[['book_title', 'book_author', 'language_code', 'publisher']], k=5):
    """
    Rekomendasi buku berdasarkan kemiripan berdasarkan title, author, language, dan publisher

    Parameter:
    ---
    nama_buku : tipe data string (str)
                Nama Buku (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan buku sebagai indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung nama, penulis, bahasa, dan penerbit untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---
    """
    # Get the index of the books with highest similarity
    index = similarity_data.loc[:, nama_buku].to_numpy().argpartition(range(-1, -k, -1))

    # Retrieve the books with the highest similarity
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop the original book from the list of recommendations
    closest = closest.drop(nama_buku, errors='ignore')

    # Return the recommendations and the closest books
    recommended_books = pd.DataFrame(closest).merge(items, on='book_title').head(k)

    return recommended_books, closest.tolist()

# Example usage
nama_buku = df.sample(1).iloc[0]
print("Judul buku: ", nama_buku.book_title)
print("Penulis buku: ", nama_buku.book_author)

# Mengambil rekomendasi
recommended_books, closest_books = book_recommendations(nama_buku.book_title, k=20)

# Menampilkan rekomendasi
print("Buku yang mungkin disukai berdasarkan kemiripan:")
recommended_books

"""Didapatkan hasil rekomendasi 20 buku teratas

# Evaluasi Precision@20
"""

# Function to calculate Precision@k
def precision_at_k(recommended_items, relevant_items, k):
    """
    Menghitung Precision@k untuk satu pengguna.

    Args:
      recommended_items: List item yang direkomendasikan.
      relevant_items: List item yang relevan bagi pengguna.
      k: Jumlah rekomendasi teratas yang dipertimbangkan.

    Returns:
      Nilai Precision@k.
    """
    recommended_at_k = recommended_items[:k]
    relevant_at_k = [item for item in recommended_at_k if item in relevant_items]
    return len(relevant_at_k) / k if k > 0 else 0

# Evaluasi Precision@20
relevant_items_for_example_user = closest_books
recommended_items_for_example_user = recommended_books['book_title'].tolist()

k_value = 20 # Evaluasi pada k=20

precision_20 = precision_at_k(recommended_items_for_example_user, relevant_items_for_example_user, k_value)

print(f"Precision@{k_value} untuk buku '{nama_buku.book_title}': {precision_20:.2f}")

"""Hasil Precision@20 = 1.00 pada peubah gabungan (judul, penulis, bahasa, dan penerbit) berarti bahwa sistem sangat baik dalam memberikan rekomendasi yang relevan, dengan semua buku yang direkomendasikan memiliki kemiripan tinggi dengan buku yang diberikan berdasarkan gabungan berbagai peubah. Ini menunjukkan bahwa sistem sangat efisien dan akurat dalam menyarankan buku-buku yang paling mirip dengan buku yang diberikan oleh pengguna.

# Evaluasi Setiap Peubah
"""

features_to_evaluate = ['book_title', 'book_author', 'language_code', 'publisher']
precision_results = {}
df_eval = df.copy()


for feature in features_to_evaluate:
    print(f"\nEvaluating Precision@20 for feature: {feature}")

    df_eval['combined_features_single'] = df_eval[feature]

    tfidf_single = TfidfVectorizer(stop_words='english')
    tfidf_matrix_single = tfidf_single.fit_transform(df_eval['combined_features_single'])
    cosine_sim_single = cosine_similarity(tfidf_matrix_single)
    cosine_sim_df_single = pd.DataFrame(cosine_sim_single, index=df_eval['book_title'], columns=df_eval['book_title'])

    recommended_books_single, closest_books_single = book_recommendations(
        nama_buku.book_title,
        similarity_data=cosine_sim_df_single,
        items=df_eval[['book_title', 'book_author', 'language_code', 'publisher']],
        k=20  # Use k=20 for evaluation
    )

    print("Buku yang mungkin disukai berdasarkan kemiripan (fitur tunggal):")
    print(recommended_books_single)

    precision_single = precision_at_k(recommended_books_single['book_title'].tolist(), closest_books_single, k=20)
    print(f"Precision@20 for {feature}: {precision_single:.2f}")

    precision_results[feature] = precision_single

precision_df = pd.DataFrame.from_dict(precision_results, orient='index', columns=['Precision@20'])

print("\nPrecision@20 based on combined features (evaluated per listed feature):")
display(precision_df)

"""Pada setiap fitur yang dievaluasi, yaitu book_title, book_author, language_code, dan publisher, nilai Precision@20 yang diperoleh adalah 1.00. Ini menunjukkan bahwa semua buku yang direkomendasikan berada dalam kategori yang relevan dengan buku yang diberikan, sesuai dengan fitur yang digunakan untuk menghitung kemiripan.

Precision@20 adalah metrik evaluasi yang mengukur sejauh mana rekomendasi yang diberikan relevan dengan item yang seharusnya relevan berdasarkan urutan kemiripan yang dihitung oleh sistem. Precision@20 dihitung dengan membandingkan 20 rekomendasi teratas dengan buku-buku yang relevan. Nilai 1.00 menunjukkan bahwa semua 20 rekomendasi teratas adalah relevan menurut kriteria fitur yang diuji (judul, penulis, kode bahasa, dan penerbit).

Precision@20 adalah metrik yang mengukur prosentase rekomendasi yang relevan di antara 20 buku teratas yang disarankan oleh sistem. Dalam konteks ini, nilai 1.00 berarti bahwa semua 20 rekomendasi teratas yang diberikan oleh sistem adalah relevan, sesuai dengan kriteria kemiripan yang dihitung berdasarkan peubah tertentu (judul, penulis, bahasa, dan penerbit).

Evaluasi berdasarkan peubah:
book_title (Judul Buku): Nilai Precision@20 untuk peubah judul adalah 1.00. Ini menunjukkan bahwa 20 buku yang direkomendasikan berdasarkan kesamaan judul semuanya relevan dengan buku yang diberikan.

book_author (Penulis): Nilai Precision@20 untuk peubah penulis juga 1.00. Ini berarti bahwa 20 buku teratas yang direkomendasikan berdasarkan kemiripan penulis juga relevan.

language_code (Kode Bahasa): Nilai Precision@20 untuk peubah kode bahasa juga 1.00. Ini menunjukkan bahwa rekomendasi buku berdasarkan kemiripan bahasa juga seluruhnya relevan.

publisher (Penerbit): Nilai Precision@20 untuk peubah penerbit adalah 1.00. Hal ini menunjukkan bahwa buku-buku yang direkomendasikan berdasarkan kesamaan penerbit juga semuanya relevan.

Interpretasi:
Nilai Precision@20 yang tinggi (1.00) untuk setiap peubah (judul, penulis, bahasa, dan penerbit) menunjukkan bahwa sistem rekomendasi ini sangat akurat dalam menemukan buku yang relevan dengan buku yang diberikan berdasarkan kemiripan pada setiap peubah tersebut.

Hasil ini mengindikasikan bahwa sistem rekomendasi sangat efektif dalam memanfaatkan berbagai informasi (judul, penulis, bahasa, dan penerbit) untuk menghasilkan rekomendasi yang sangat relevan dengan buku yang menjadi acuan.

Semua 20 rekomendasi teratas untuk setiap peubah menunjukkan kemiripan yang sangat baik dengan buku yang diberikan. Dengan kata lain, sistem rekomendasi berhasil menyarankan buku-buku yang berkaitan erat dengan "The Story of Philosophy: A Concise Introduction to the World's Greatest Thinkers and Their Ideas", berdasarkan judul, penulis, kode bahasa, dan penerbit. Ini menunjukkan bahwa model rekomendasi yang digunakan cukup handal dalam menghasilkan rekomendasi yang relevan.
"""